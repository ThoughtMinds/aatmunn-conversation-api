from typing_extensions import List, TypedDict
from typing import Optional, AsyncGenerator, Dict
from langchain_core.documents import Document
from api import rag, llm, schema
from langgraph.graph import START, StateGraph
import json
from api.core.logging_config import logger


class State(TypedDict):
    """
    Represents the state of the graph.

    Attributes:
        query (str): The query being asked.
        context (List[Document]): A list of documents retrieved from the vector store.
        navigation (schema.Navigation): The navigation information generated by the model.
    """

    query: str
    context: List[Document]
    navigation: schema.Navigation


def retrieve(state: State):
    """
    Retrieves documents from the vector store based on the query in the state.

    Args:
        state (State): The current state of the graph.

    Returns:
        dict: A dictionary containing the retrieved documents in the 'context' key.
    """
    vectorstore = rag.get_vectorstore()
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    retrieved_docs = retriever.invoke(input=state["query"])
    logger.info(f"Retrieved {len(retrieved_docs)} documents")
    return {"context": retrieved_docs}


def generate(state: State):
    """
    Generates a navigation response based on the retrieved context and the query.

    Args:
        state (State): The current state of the graph.

    Returns:
        dict: A dictionary containing the generated navigation information in the 'navigation' key.
    """
    context = {}
    id_mapping = {}
    for i, doc in enumerate(state["context"], start=1):
        id_mapping[i] = doc.id
        context[i] = {
            "id": i,
            "description": doc.page_content,
        }

    logger.info(f"Processing context with {len(context)} documents")
    try:
        chat_model = llm.get_ollama_chat_fallback_model()
        rag_chain = llm.create_chain_for_task(
            task="navigation", llm=chat_model, output_schema=schema.Navigation
        )
        response = rag_chain.invoke(
            {"query": state["query"], "context": json.dumps(context)}
        )
        if response:
            id = response.id
            response.id = id_mapping.get(id, None)
            return {"navigation": response}
    except Exception as e:
        logger.error(f"Failed to get Navigation due to: {e}")
        return {
            "navigation": schema.Navigation(
                reasoning="Unable to generate navigation response. Please try again.",
                id=None,
            )
        }


graph_builder = StateGraph(State).add_sequence([retrieve, generate])
graph_builder.add_edge(START, "retrieve")
navigation_graph = graph_builder.compile()


def get_navigation_response(
    query: str, chained: bool = False
) -> Optional[schema.Navigation]:
    """
    Generates a navigation response for a given query using a LangGraph workflow.

    Args:
        query (str): The user's query for navigation.
        chained (bool): This parameter is ignored, but included for compatibility.

    Returns:
        schema.Navigation: The navigation response, or None if no response is generated.
    """
    initial_state = {"query": query}
    result = navigation_graph.invoke(initial_state)
    return result.get("navigation")


async def get_streaming_navigation_response(
    query: str, chained: bool = False
) -> AsyncGenerator[Dict, None]:
    """
    Generates a navigation response for a given query using a LangGraph workflow with streaming.
    """
    logger.info("Generating streaming navigation response")
    initial_state = {"query": query, "context": [], "navigation": None}

    try:
        async for event in navigation_graph.astream(initial_state):
            for value in event.values():
                state_update = {}

                if "context" in value:
                    state_update["context"] = [
                        {
                            "id": doc.id,
                            "content": (
                                doc.page_content[:200] + "..."
                                if len(doc.page_content) > 200
                                else doc.page_content
                            ),
                        }
                        for doc in value["context"]
                    ]

                if "navigation" in value and value["navigation"]:
                    nav = value["navigation"]
                    state_update["navigation"] = {
                        "reasoning": nav.reasoning,
                        "id": nav.id,
                    }
                    # Add final_response for navigation completion
                    state_update["final_response"] = nav.reasoning

                yield state_update

    except Exception as e:
        logger.error(f"Error in streaming navigation: {e}")
        yield {"error": str(e)}
